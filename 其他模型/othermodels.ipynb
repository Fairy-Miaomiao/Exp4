{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b2e0195",
   "metadata": {},
   "source": [
    "# 导包和环境配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31d560a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark import SQLContext\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.classification import RandomForestClassifier,NaiveBayes,DecisionTreeClassifier,GBTClassifier,OneVsRest,LogisticRegression,LogisticRegressionSummary,MultilayerPerceptronClassifier\n",
    "from pyspark.sql.types import IntegerType\n",
    "sc = SparkContext(\"local\", \"first\")\n",
    "logFile = \"file:///F:/FBDP/实验/实验四/logfile1.txt\"  \n",
    "logData = sc.textFile(logFile).cache()\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"16g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1d56d5",
   "metadata": {},
   "source": [
    "# 读入数据并填补缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f45ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.options(header='True') .csv(\"file:///F:/FBDP/实验/实验四/train_data.csv\")\n",
    "df = df.na.fill(-1)\n",
    "df = df.na.fill('-1')\n",
    "df=df.withColumnRenamed(\"is_default\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af83509",
   "metadata": {},
   "source": [
    "# 把categorical变量转换为数值(略显粗暴)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfa181ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----------+------------+--------+---------------+-----+---------+---------+-------------+------------------------------+---------+-----------+-----------------+-------------+--------+----------+----------+---+---------+------+---------------+--------------+-----------+------------+----------------+------------+-------------------+------------------------+----------+----------+-------------------+------------------+-----+-----------+---+---+----+----+---+---+-----+---------+-------------+-------------+----------------+-------------+----------------+-----------------+--------------------+------------+---------------+-------------+----------------+--------------+-----------------+----------------------+-------------------------+\n",
      "|loan_id|user_id|total_loan|year_of_loan|interest|monthly_payment|class|sub_class|work_type|employer_type|                      industry|work_year|house_exist|house_loan_status|censor_status|marriage|offsprings|issue_date|use|post_code|region|debt_loan_ratio|del_in_18month|scoring_low|scoring_high|pub_dero_bankrup|early_return|early_return_amount|early_return_amount_3mon|recircle_b|recircle_u|initial_list_status|earlies_credit_mon|title|policy_code| f0| f1|  f2|  f3| f4| f5|label|class_num| class_vector|sub_class_num|sub_class_vector|work_type_num|work_type_vector|employer_type_num|employer_type_vector|industry_num|industry_vector|work_year_num|work_year_vector|issue_date_num|issue_date_vector|earlies_credit_mon_num|earlies_credit_mon_vector|\n",
      "+-------+-------+----------+------------+--------+---------------+-----+---------+---------+-------------+------------------------------+---------+-----------+-----------------+-------------+--------+----------+----------+---+---------+------+---------------+--------------+-----------+------------+----------------+------------+-------------------+------------------------+----------+----------+-------------------+------------------+-----+-----------+---+---+----+----+---+---+-----+---------+-------------+-------------+----------------+-------------+----------------+-----------------+--------------------+------------+---------------+-------------+----------------+--------------+-----------------+----------------------+-------------------------+\n",
      "| 119262|      0|   12000.0|           5|   11.53|          264.1|    B|       B5|     职员|     普通企业|                        采矿业|       -1|          0|                0|            2|       0|         0|2015-06-01|  0|    814.0|     4|           5.07|           1.0|      670.0|       674.0|             1.0|           0|                  0|                     0.0|    3855.0|      23.1|                  0|          Mar-1984|  0.0|        1.0|1.0|0.0| 8.0|17.0|8.0|1.0|    1|      0.0|(6,[0],[1.0])|          2.0|  (34,[2],[1.0])|          1.0|   (4,[1],[1.0])|              0.0|       (5,[0],[1.0])|         9.0| (13,[9],[1.0])|          7.0|  (11,[7],[1.0])|          13.0| (137,[13],[1.0])|                 335.0|        (685,[335],[1.0])|\n",
      "| 369815|      1|    8000.0|           3|   13.98|         273.35|    C|       C3|     其他|     普通企业|                      国际组织|10+ years|          0|                1|            2|       1|         3|2010-10-01|  2|    240.0|    21|          15.04|           0.0|      725.0|       729.0|             0.0|           0|                  0|                     0.0|  118632.0|      99.9|                  1|          Jan-1992| 94.0|        1.0| -1| -1|  -1|  -1| -1| -1|    0|      1.0|(6,[1],[1.0])|          6.0|  (34,[6],[1.0])|          0.0|   (4,[0],[1.0])|              0.0|       (5,[0],[1.0])|        11.0|(13,[11],[1.0])|          0.0|  (11,[0],[1.0])|          98.0| (137,[98],[1.0])|                 248.0|        (685,[248],[1.0])|\n",
      "| 787833|      2|   20000.0|           5|   17.99|         507.76|    D|       D2|     工人|     上市企业|信息传输、软件和信息技术服务业|10+ years|          0|                0|            1|       0|         0|2016-08-01|  0|    164.0|    20|          17.38|           1.0|      675.0|       679.0|             0.0|           0|                  0|                     0.0|   15670.0|      72.5|                  0|          Oct-1996|  0.0|        1.0|6.0|0.0|10.0| 8.0|3.0|0.0|    0|      3.0|(6,[3],[1.0])|         13.0| (34,[13],[1.0])|          2.0|   (4,[2],[1.0])|              2.0|       (5,[2],[1.0])|         5.0| (13,[5],[1.0])|          0.0|  (11,[0],[1.0])|          18.0| (137,[18],[1.0])|                  90.0|         (685,[90],[1.0])|\n",
      "+-------+-------+----------+------------+--------+---------------+-----+---------+---------+-------------+------------------------------+---------+-----------+-----------------+-------------+--------+----------+----------+---+---------+------+---------------+--------------+-----------+------------+----------------+------------+-------------------+------------------------+----------+----------+-------------------+------------------+-----+-----------+---+---+----+----+---+---+-----+---------+-------------+-------------+----------------+-------------+----------------+-----------------+--------------------+------------+---------------+-------------+----------------+--------------+-----------------+----------------------+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#class\n",
    "class_indexer = StringIndexer(inputCol='class', outputCol='class_num').fit(df)\n",
    "df = class_indexer.transform(df)\n",
    "class_onehoter = OneHotEncoder(inputCol='class_num', outputCol='class_vector')\n",
    "df = class_onehoter.transform(df)\n",
    "#sub_class\n",
    "sub_class_indexer = StringIndexer(inputCol='sub_class', outputCol='sub_class_num').fit(df)\n",
    "df = sub_class_indexer.transform(df)\n",
    "sub_class_onehoter = OneHotEncoder(inputCol='sub_class_num', outputCol='sub_class_vector')\n",
    "df = sub_class_onehoter.transform(df)\n",
    "#work_type\n",
    "work_type_indexer = StringIndexer(inputCol='work_type', outputCol='work_type_num').fit(df)\n",
    "df = work_type_indexer.transform(df)\n",
    "work_type_onehoter = OneHotEncoder(inputCol='work_type_num', outputCol='work_type_vector')\n",
    "df = work_type_onehoter.transform(df)\n",
    "#employer_type\n",
    "employer_type_indexer = StringIndexer(inputCol='employer_type', outputCol='employer_type_num').fit(df)\n",
    "df = employer_type_indexer.transform(df)\n",
    "employer_type_onehoter = OneHotEncoder(inputCol='employer_type_num', outputCol='employer_type_vector')\n",
    "df = employer_type_onehoter.transform(df)\n",
    "#industry\n",
    "industry_indexer = StringIndexer(inputCol='industry', outputCol='industry_num').fit(df)\n",
    "df = industry_indexer.transform(df)\n",
    "industry_onehoter = OneHotEncoder(inputCol='industry_num', outputCol='industry_vector')\n",
    "df = industry_onehoter.transform(df)\n",
    "#work_year\n",
    "work_year_indexer = StringIndexer(inputCol='work_year', outputCol='work_year_num').fit(df)\n",
    "df = work_year_indexer.transform(df)\n",
    "work_year_onehoter = OneHotEncoder(inputCol='work_year_num', outputCol='work_year_vector')\n",
    "df = work_year_onehoter.transform(df)\n",
    "#df.show(3)\n",
    "#issue_date\n",
    "issue_date_indexer = StringIndexer(inputCol='issue_date', outputCol='issue_date_num').fit(df)\n",
    "df = issue_date_indexer.transform(df)\n",
    "issue_date_onehoter = OneHotEncoder(inputCol='issue_date_num', outputCol='issue_date_vector')\n",
    "df = issue_date_onehoter.transform(df)\n",
    "#df.show(3)\n",
    "#earlies_credit_mon\n",
    "earlies_credit_mon_indexer = StringIndexer(inputCol='earlies_credit_mon', outputCol='earlies_credit_mon_num').fit(df)\n",
    "df = earlies_credit_mon_indexer.transform(df)\n",
    "earlies_credit_mon_onehoter = OneHotEncoder(inputCol='earlies_credit_mon_num', outputCol='earlies_credit_mon_vector')\n",
    "df = earlies_credit_mon_onehoter.transform(df)\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f258442",
   "metadata": {},
   "source": [
    "# 把string列转为int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efcd15ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "+-------+-------+----------+------------+--------+---------------+-----+---------+---------+-------------+------------------------------+---------+-----------+-----------------+-------------+--------+----------+----------+---+---------+------+---------------+--------------+-----------+------------+----------------+------------+-------------------+------------------------+----------+----------+-------------------+------------------+-----+-----------+----+----+----+----+----+----+-----+---------+-------------+-------------+----------------+-------------+----------------+-----------------+--------------------+------------+---------------+-------------+----------------+--------------+-----------------+----------------------+-------------------------+\n",
      "|loan_id|user_id|total_loan|year_of_loan|interest|monthly_payment|class|sub_class|work_type|employer_type|                      industry|work_year|house_exist|house_loan_status|censor_status|marriage|offsprings|issue_date|use|post_code|region|debt_loan_ratio|del_in_18month|scoring_low|scoring_high|pub_dero_bankrup|early_return|early_return_amount|early_return_amount_3mon|recircle_b|recircle_u|initial_list_status|earlies_credit_mon|title|policy_code|  f0|  f1|  f2|  f3|  f4|  f5|label|class_num| class_vector|sub_class_num|sub_class_vector|work_type_num|work_type_vector|employer_type_num|employer_type_vector|industry_num|industry_vector|work_year_num|work_year_vector|issue_date_num|issue_date_vector|earlies_credit_mon_num|earlies_credit_mon_vector|\n",
      "+-------+-------+----------+------------+--------+---------------+-----+---------+---------+-------------+------------------------------+---------+-----------+-----------------+-------------+--------+----------+----------+---+---------+------+---------------+--------------+-----------+------------+----------------+------------+-------------------+------------------------+----------+----------+-------------------+------------------+-----+-----------+----+----+----+----+----+----+-----+---------+-------------+-------------+----------------+-------------+----------------+-----------------+--------------------+------------+---------------+-------------+----------------+--------------+-----------------+----------------------+-------------------------+\n",
      "| 119262|      0|   12000.0|         5.0|   11.53|          264.1|    B|       B5|     职员|     普通企业|                        采矿业|       -1|        0.0|              0.0|          2.0|     0.0|       0.0|2015-06-01|0.0|    814.0|   4.0|           5.07|           1.0|      670.0|       674.0|             1.0|         0.0|                0.0|                     0.0|    3855.0|      23.1|                0.0|          Mar-1984|  0.0|        1.0| 1.0| 0.0| 8.0|17.0| 8.0| 1.0|    1|      0.0|(6,[0],[1.0])|          2.0|  (34,[2],[1.0])|          1.0|   (4,[1],[1.0])|              0.0|       (5,[0],[1.0])|         9.0| (13,[9],[1.0])|          7.0|  (11,[7],[1.0])|          13.0| (137,[13],[1.0])|                 335.0|        (685,[335],[1.0])|\n",
      "| 369815|      1|    8000.0|         3.0|   13.98|         273.35|    C|       C3|     其他|     普通企业|                      国际组织|10+ years|        0.0|              1.0|          2.0|     1.0|       3.0|2010-10-01|2.0|    240.0|  21.0|          15.04|           0.0|      725.0|       729.0|             0.0|         0.0|                0.0|                     0.0|  118632.0|      99.9|                1.0|          Jan-1992| 94.0|        1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|    0|      1.0|(6,[1],[1.0])|          6.0|  (34,[6],[1.0])|          0.0|   (4,[0],[1.0])|              0.0|       (5,[0],[1.0])|        11.0|(13,[11],[1.0])|          0.0|  (11,[0],[1.0])|          98.0| (137,[98],[1.0])|                 248.0|        (685,[248],[1.0])|\n",
      "| 787833|      2|   20000.0|         5.0|   17.99|         507.76|    D|       D2|     工人|     上市企业|信息传输、软件和信息技术服务业|10+ years|        0.0|              0.0|          1.0|     0.0|       0.0|2016-08-01|0.0|    164.0|  20.0|          17.38|           1.0|      675.0|       679.0|             0.0|         0.0|                0.0|                     0.0|   15670.0|      72.5|                0.0|          Oct-1996|  0.0|        1.0| 6.0| 0.0|10.0| 8.0| 3.0| 0.0|    0|      3.0|(6,[3],[1.0])|         13.0| (34,[13],[1.0])|          2.0|   (4,[2],[1.0])|              2.0|       (5,[2],[1.0])|         5.0| (13,[5],[1.0])|          0.0|  (11,[0],[1.0])|          18.0| (137,[18],[1.0])|                  90.0|         (685,[90],[1.0])|\n",
      "+-------+-------+----------+------------+--------+---------------+-----+---------+---------+-------------+------------------------------+---------+-----------+-----------------+-------------+--------+----------+----------+---+---------+------+---------------+--------------+-----------+------------+----------------+------------+-------------------+------------------------+----------+----------+-------------------+------------------+-----+-----------+----+----+----+----+----+----+-----+---------+-------------+-------------+----------------+-------------+----------------+-----------------+--------------------+------------+---------------+-------------+----------------+--------------+-----------------+----------------------+-------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tmpCols=['total_loan', 'year_of_loan', 'interest', 'monthly_payment', 'class_vector','sub_class_vector','work_type_vector','employer_type_vector','industry_vector','issue_date_vector','earlies_credit_mon_vector','house_exist','house_loan_status','censor_status','marriage','offsprings','use','post_code','region','debt_loan_ratio','del_in_18month','scoring_low','scoring_high','pub_dero_bankrup','early_return','early_return_amount','early_return_amount_3mon','recircle_b','recircle_u','initial_list_status','title','policy_code','f0','f1','f2','f3','f4','f5']\n",
    "for i in tmpCols:\n",
    "    if \"vector\" in i:\n",
    "        print(\"\")\n",
    "    else:\n",
    "        df = df.withColumn(i, df[i].cast('double'))\n",
    "#df = df.withColumn(\"total_loan\", df[\"total_loan\"].cast(IntegerType()))\n",
    "df = df.withColumn('label', df['label'].cast(IntegerType()))\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235ed7cb",
   "metadata": {},
   "source": [
    "# 把输入特征合并到一列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "727157d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VectorAssembler_1b84fdf45a05\n",
      "+-------+-------+----------+------------+--------+---------------+-----+---------+---------+--------------+------------------------------+---------+-----------+-----------------+-------------+--------+----------+----------+---+---------+------+---------------+--------------+-----------+------------+----------------+------------+-------------------+------------------------+----------+----------+-------------------+------------------+-------+-----------+----+----+----+----+----+----+-----+---------+-------------+-------------+----------------+-------------+----------------+-----------------+--------------------+------------+---------------+-------------+----------------+--------------+-----------------+----------------------+-------------------------+--------------------+\n",
      "|loan_id|user_id|total_loan|year_of_loan|interest|monthly_payment|class|sub_class|work_type| employer_type|                      industry|work_year|house_exist|house_loan_status|censor_status|marriage|offsprings|issue_date|use|post_code|region|debt_loan_ratio|del_in_18month|scoring_low|scoring_high|pub_dero_bankrup|early_return|early_return_amount|early_return_amount_3mon|recircle_b|recircle_u|initial_list_status|earlies_credit_mon|  title|policy_code|  f0|  f1|  f2|  f3|  f4|  f5|label|class_num| class_vector|sub_class_num|sub_class_vector|work_type_num|work_type_vector|employer_type_num|employer_type_vector|industry_num|industry_vector|work_year_num|work_year_vector|issue_date_num|issue_date_vector|earlies_credit_mon_num|earlies_credit_mon_vector|            features|\n",
      "+-------+-------+----------+------------+--------+---------------+-----+---------+---------+--------------+------------------------------+---------+-----------+-----------------+-------------+--------+----------+----------+---+---------+------+---------------+--------------+-----------+------------+----------------+------------+-------------------+------------------------+----------+----------+-------------------+------------------+-------+-----------+----+----+----+----+----+----+-----+---------+-------------+-------------+----------------+-------------+----------------+-----------------+--------------------+------------+---------------+-------------+----------------+--------------+-----------------+----------------------+-------------------------+--------------------+\n",
      "| 119262|      0|   12000.0|         5.0|   11.53|          264.1|    B|       B5|     职员|      普通企业|                        采矿业|       -1|        0.0|              0.0|          2.0|     0.0|       0.0|2015-06-01|0.0|    814.0|   4.0|           5.07|           1.0|      670.0|       674.0|             1.0|         0.0|                0.0|                     0.0|    3855.0|      23.1|                0.0|          Mar-1984|    0.0|        1.0| 1.0| 0.0| 8.0|17.0| 8.0| 1.0|    1|      0.0|(6,[0],[1.0])|          2.0|  (34,[2],[1.0])|          1.0|   (4,[1],[1.0])|              0.0|       (5,[0],[1.0])|         9.0| (13,[9],[1.0])|          7.0|  (11,[7],[1.0])|          13.0| (137,[13],[1.0])|                 335.0|        (685,[335],[1.0])|(926,[0,1,2,3,4,1...|\n",
      "| 369815|      1|    8000.0|         3.0|   13.98|         273.35|    C|       C3|     其他|      普通企业|                      国际组织|10+ years|        0.0|              1.0|          2.0|     1.0|       3.0|2010-10-01|2.0|    240.0|  21.0|          15.04|           0.0|      725.0|       729.0|             0.0|         0.0|                0.0|                     0.0|  118632.0|      99.9|                1.0|          Jan-1992|   94.0|        1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|    0|      1.0|(6,[1],[1.0])|          6.0|  (34,[6],[1.0])|          0.0|   (4,[0],[1.0])|              0.0|       (5,[0],[1.0])|        11.0|(13,[11],[1.0])|          0.0|  (11,[0],[1.0])|          98.0| (137,[98],[1.0])|                 248.0|        (685,[248],[1.0])|(926,[0,1,2,3,5,1...|\n",
      "| 787833|      2|   20000.0|         5.0|   17.99|         507.76|    D|       D2|     工人|      上市企业|信息传输、软件和信息技术服务业|10+ years|        0.0|              0.0|          1.0|     0.0|       0.0|2016-08-01|0.0|    164.0|  20.0|          17.38|           1.0|      675.0|       679.0|             0.0|         0.0|                0.0|                     0.0|   15670.0|      72.5|                0.0|          Oct-1996|    0.0|        1.0| 6.0| 0.0|10.0| 8.0| 3.0| 0.0|    0|      3.0|(6,[3],[1.0])|         13.0| (34,[13],[1.0])|          2.0|   (4,[2],[1.0])|              2.0|       (5,[2],[1.0])|         5.0| (13,[5],[1.0])|          0.0|  (11,[0],[1.0])|          18.0| (137,[18],[1.0])|                  90.0|         (685,[90],[1.0])|(926,[0,1,2,3,7,2...|\n",
      "| 671675|      3|   10700.0|         3.0|   10.16|         346.07|    B|       B1|     职员|      普通企业|          电力、热力生产供应业|  2 years|        2.0|              0.0|          2.0|     0.0|       0.0|2013-05-01|4.0|     48.0|  10.0|          27.87|           0.0|      710.0|       714.0|             0.0|         0.0|                0.0|                     0.0|   18859.0|      78.6|                0.0|          Jul-2000|41646.0|        1.0| 3.0| 0.0| 4.0|11.0| 6.0| 0.0|    0|      0.0|(6,[0],[1.0])|          8.0|  (34,[8],[1.0])|          1.0|   (4,[1],[1.0])|              0.0|       (5,[0],[1.0])|         1.0| (13,[1],[1.0])|          1.0|  (11,[1],[1.0])|          52.0| (137,[52],[1.0])|                  38.0|         (685,[38],[1.0])|(926,[0,1,2,3,4,1...|\n",
      "| 245160|      4|    8000.0|         3.0|    8.24|         251.58|    B|       B1|     其他|      政府机构|                        金融业|  5 years|        1.0|              2.0|          0.0|     0.0|       0.0|2017-04-01|4.0|    122.0|   9.0|           3.47|           0.0|      660.0|       664.0|             0.0|         0.0|                0.0|                     0.0|    8337.0|      67.8|                1.0|          Mar-2000|    4.0|        1.0| 3.0| 0.0| 8.0| 6.0| 4.0| 1.0|    0|      0.0|(6,[0],[1.0])|          8.0|  (34,[8],[1.0])|          0.0|   (4,[0],[1.0])|              1.0|       (5,[1],[1.0])|         0.0| (13,[0],[1.0])|          5.0|  (11,[5],[1.0])|          45.0| (137,[45],[1.0])|                  36.0|         (685,[36],[1.0])|(926,[0,1,2,3,4,1...|\n",
      "| 647107|      5|   28000.0|         3.0|   15.59|         978.74|    C|       C5|     职员|幼教与中小学校|            公共服务、社会组织|10+ years|        2.0|              0.0|          2.0|     0.0|       0.0|2016-08-01|0.0|    149.0|  22.0|          24.33|           0.0|      680.0|       684.0|             0.0|         0.0|                0.0|                     0.0|   40727.0|      88.6|                0.0|          May-2002|    0.0|        1.0| 3.0| 0.0| 6.0|10.0| 3.0| 1.0|    1|      1.0|(6,[1],[1.0])|          9.0|  (34,[9],[1.0])|          1.0|   (4,[1],[1.0])|              3.0|       (5,[3],[1.0])|         2.0| (13,[2],[1.0])|          0.0|  (11,[0],[1.0])|          18.0| (137,[18],[1.0])|                  44.0|         (685,[44],[1.0])|(926,[0,1,2,3,5,1...|\n",
      "| 289151|      6|    6000.0|         3.0|    7.89|         187.72|    A|       A5|     职员|      政府机构|信息传输、软件和信息技术服务业|  8 years|        0.0|              1.0|          0.0|     0.0|       0.0|2015-07-01|0.0|    634.0|  32.0|           8.43|           0.0|      710.0|       714.0|             0.0|         0.0|                0.0|                     0.0|     724.0|      14.2|                1.0|          Aug-2000|    0.0|        1.0| 3.0| 0.0|13.0| 5.0| 5.0| 1.0|    0|      2.0|(6,[2],[1.0])|         10.0| (34,[10],[1.0])|          1.0|   (4,[1],[1.0])|              1.0|       (5,[1],[1.0])|         5.0| (13,[5],[1.0])|          9.0|  (11,[9],[1.0])|           2.0|  (137,[2],[1.0])|                   5.0|          (685,[5],[1.0])|(926,[0,1,2,3,6,2...|\n",
      "| 750155|      7|   20000.0|         3.0|   12.79|         671.86|    C|       C1|   工程师|      上市企业|                        金融业|10+ years|        0.0|              0.0|          2.0|     0.0|       0.0|2016-07-01|0.0|    197.0|   4.0|          19.48|           0.0|      690.0|       694.0|             0.0|         0.0|                0.0|                     0.0|   16694.0|      71.6|                0.0|          Oct-2005|    0.0|        1.0| 8.0| 0.0| 3.0|12.0| 8.0| 0.0|    0|      1.0|(6,[1],[1.0])|          0.0|  (34,[0],[1.0])|          4.0|       (4,[],[])|              2.0|       (5,[2],[1.0])|         0.0| (13,[0],[1.0])|          0.0|  (11,[0],[1.0])|          19.0| (137,[19],[1.0])|                  59.0|         (685,[59],[1.0])|(926,[0,1,2,3,5,1...|\n",
      "| 387697|      8|    9450.0|         3.0|   13.11|         318.91|    B|       B4|     工人|      政府机构|信息传输、软件和信息技术服务业|  2 years|        0.0|              0.0|          0.0|     1.0|       0.0|2012-08-01|4.0|     19.0|  14.0|          18.64|           0.0|      705.0|       709.0|             0.0|         0.0|                0.0|                     0.0|   14291.0|      66.5|                1.0|          Apr-2001|  847.0|        1.0|-1.0|-1.0|-1.0|-1.0|-1.0|-1.0|    0|      0.0|(6,[0],[1.0])|          1.0|  (34,[1],[1.0])|          2.0|   (4,[2],[1.0])|              1.0|       (5,[1],[1.0])|         5.0| (13,[5],[1.0])|          1.0|  (11,[1],[1.0])|          69.0| (137,[69],[1.0])|                  45.0|         (685,[45],[1.0])|(926,[0,1,2,3,4,1...|\n",
      "| 186940|      9|    4500.0|         3.0|    5.32|         135.52|    A|       A1|     其他|  高等教育机构|                  文化和体育业|10+ years|        0.0|              0.0|          0.0|     1.0|       0.0|2017-02-01|9.0|    468.0|   0.0|            7.4|           0.0|      805.0|       809.0|             0.0|         0.0|                0.0|                     0.0|    1623.0|      10.5|                0.0|          Sep-1992|   10.0|        1.0| 2.0| 0.0| 9.0| 8.0| 2.0| 0.0|    0|      2.0|(6,[2],[1.0])|         14.0| (34,[14],[1.0])|          0.0|   (4,[0],[1.0])|              5.0|           (5,[],[])|         4.0| (13,[4],[1.0])|          0.0|  (11,[0],[1.0])|          44.0| (137,[44],[1.0])|                 189.0|        (685,[189],[1.0])|(926,[0,1,2,3,6,2...|\n",
      "| 740415|     10|   21850.0|         3.0|   11.44|         719.91|    B|       B4|     职员|    世界五百强|                        建筑业|10+ years|        0.0|              0.0|          2.0|     1.0|       3.0|2016-11-01|0.0|    466.0|  36.0|          27.67|           0.0|      725.0|       729.0|             0.0|        14.0|              840.0|      183.73377634804947|  501094.0|      53.2|                0.0|          Feb-1986|    0.0|        1.0| 3.0| 0.0|14.0| 6.0| 2.0| 0.0|    0|      0.0|(6,[0],[1.0])|          1.0|  (34,[1],[1.0])|          1.0|   (4,[1],[1.0])|              4.0|       (5,[4],[1.0])|         6.0| (13,[6],[1.0])|          0.0|  (11,[0],[1.0])|          24.0| (137,[24],[1.0])|                 325.0|        (685,[325],[1.0])|(926,[0,1,2,3,4,1...|\n",
      "| 573270|     11|   10500.0|         3.0|   10.99|         343.71|    B|       B4|     职员|      政府机构|信息传输、软件和信息技术服务业|  3 years|        1.0|              1.0|          1.0|     1.0|       0.0|2015-04-01|0.0|     33.0|  22.0|          17.49|           0.0|      705.0|       709.0|             0.0|         0.0|                0.0|                     0.0|   14325.0|      74.6|                0.0|          Aug-2004|    0.0|        1.0| 9.0| 0.0| 3.0|15.0| 8.0| 0.0|    0|      0.0|(6,[0],[1.0])|          1.0|  (34,[1],[1.0])|          1.0|   (4,[1],[1.0])|              1.0|       (5,[1],[1.0])|         5.0| (13,[5],[1.0])|          3.0|  (11,[3],[1.0])|           7.0|  (137,[7],[1.0])|                  10.0|         (685,[10],[1.0])|(926,[0,1,2,3,4,1...|\n",
      "| 607714|     12|   22000.0|         3.0|   15.61|         769.23|    D|       D1|     其他|      政府机构|                  文化和体育业|   1 year|        0.0|              0.0|          1.0|     1.0|       0.0|2015-03-01|0.0|    765.0|  39.0|          27.49|           0.0|      680.0|       684.0|             1.0|         0.0|                0.0|                     0.0|   23455.0|      29.8|                1.0|          Jul-1996|    0.0|        1.0|13.0| 0.0| 5.0|39.0|19.0| 0.0|    0|      3.0|(6,[3],[1.0])|         12.0| (34,[12],[1.0])|          0.0|   (4,[0],[1.0])|              1.0|       (5,[1],[1.0])|         4.0| (13,[4],[1.0])|          4.0|  (11,[4],[1.0])|          17.0| (137,[17],[1.0])|                 145.0|        (685,[145],[1.0])|(926,[0,1,2,3,7,2...|\n",
      "| 405331|     13|    9600.0|         3.0|    8.18|         301.63|    B|       B1|     职员|      普通企业|                        金融业| < 1 year|        1.0|              1.0|          1.0|     0.0|       0.0|2015-08-01|4.0|    157.0|   8.0|          18.73|           0.0|      680.0|       684.0|             0.0|         0.0|                0.0|                     0.0|    7038.0|      58.6|                0.0|          Feb-2001|    4.0|        1.0| 8.0| 0.0| 4.0| 8.0| 3.0| 0.0|    1|      0.0|(6,[0],[1.0])|          8.0|  (34,[8],[1.0])|          1.0|   (4,[1],[1.0])|              0.0|       (5,[0],[1.0])|         0.0| (13,[0],[1.0])|          2.0|  (11,[2],[1.0])|           9.0|  (137,[9],[1.0])|                  57.0|         (685,[57],[1.0])|(926,[0,1,2,3,4,1...|\n",
      "| 477316|     14|   16000.0|         5.0|   14.99|         380.56|    C|       C4|   公务员|幼教与中小学校|                  住宿和餐饮业|  4 years|        0.0|              1.0|          1.0|     0.0|       0.0|2017-04-01|0.0|    152.0|  14.0|          16.52|           0.0|      690.0|       694.0|             0.0|         0.0|                0.0|                     0.0|   11375.0|      35.0|                0.0|          Oct-1993|    0.0|        1.0| 7.0|-1.0| 5.0|17.0| 8.0| 0.0|    0|      1.0|(6,[1],[1.0])|          7.0|  (34,[7],[1.0])|          3.0|   (4,[3],[1.0])|              3.0|       (5,[3],[1.0])|         3.0| (13,[3],[1.0])|          6.0|  (11,[6],[1.0])|          45.0| (137,[45],[1.0])|                 157.0|        (685,[157],[1.0])|(926,[0,1,2,3,5,1...|\n",
      "| 325317|     15|   17075.0|         5.0|   18.55|         438.72|    E|       E2|     其他|      普通企业|                        建筑业|  7 years|        0.0|              1.0|          1.0|     0.0|       0.0|2015-08-01|0.0|    195.0|  38.0|          34.07|           0.0|      695.0|       699.0|             0.0|         0.0|                0.0|                     0.0|   28938.0|      70.2|                0.0|          Jan-1985|    0.0|        1.0| 6.0| 0.0| 7.0|18.0| 8.0| 0.0|    1|      4.0|(6,[4],[1.0])|         21.0| (34,[21],[1.0])|          0.0|   (4,[0],[1.0])|              0.0|       (5,[0],[1.0])|         6.0| (13,[6],[1.0])|         10.0| (11,[10],[1.0])|           9.0|  (137,[9],[1.0])|                 331.0|        (685,[331],[1.0])|(926,[0,1,2,3,8,3...|\n",
      "| 487138|     16|   28675.0|         3.0|   13.18|         968.67|    C|       C3|     其他|      普通企业|          电力、热力生产供应业|10+ years|        1.0|              1.0|          2.0|     0.0|       0.0|2015-11-01|0.0|    156.0|  18.0|          17.69|           1.0|      675.0|       679.0|             0.0|         0.0|                0.0|                     0.0|   45154.0|      62.3|                1.0|          Oct-1992|    0.0|        1.0| 4.0| 0.0|12.0| 8.0| 4.0| 0.0|    1|      1.0|(6,[1],[1.0])|          6.0|  (34,[6],[1.0])|          0.0|   (4,[0],[1.0])|              0.0|       (5,[0],[1.0])|         1.0| (13,[1],[1.0])|          0.0|  (11,[0],[1.0])|           6.0|  (137,[6],[1.0])|                 181.0|        (685,[181],[1.0])|(926,[0,1,2,3,5,1...|\n",
      "| 772918|     17|    5925.0|         3.0|   13.49|         201.04|    C|       C2|     其他|    世界五百强|                  住宿和餐饮业|10+ years|        1.0|              0.0|          0.0|     1.0|       0.0|2016-10-01|4.0|    163.0|  21.0|          11.52|           1.0|      670.0|       674.0|             0.0|         0.0|                0.0|                     0.0|    9192.0|      62.1|                0.0|          Jan-1997|    4.0|        1.0| 6.0| 0.0| 5.0| 8.0| 6.0| 2.0|    0|      1.0|(6,[1],[1.0])|          4.0|  (34,[4],[1.0])|          0.0|   (4,[0],[1.0])|              4.0|       (5,[4],[1.0])|         3.0| (13,[3],[1.0])|          0.0|  (11,[0],[1.0])|          23.0| (137,[23],[1.0])|                 146.0|        (685,[146],[1.0])|(926,[0,1,2,3,5,1...|\n",
      "| 470805|     18|   12000.0|         5.0|   14.99|         285.42|    C|       C4|   公务员|      普通企业|                      国际组织|10+ years|        0.0|              0.0|          1.0|     1.0|       5.0|2016-11-01|0.0|    512.0|  21.0|          13.79|           0.0|      675.0|       679.0|             1.0|         0.0|                0.0|                     0.0|    9060.0|      41.6|                0.0|          May-1998|    0.0|        1.0| 8.0| 0.0| 5.0|17.0|10.0| 4.0|    0|      1.0|(6,[1],[1.0])|          7.0|  (34,[7],[1.0])|          3.0|   (4,[3],[1.0])|              0.0|       (5,[0],[1.0])|        11.0|(13,[11],[1.0])|          0.0|  (11,[0],[1.0])|          24.0| (137,[24],[1.0])|                 109.0|        (685,[109],[1.0])|(926,[0,1,2,3,5,1...|\n",
      "| 402970|     19|    9600.0|         3.0|    7.91|         300.44|    A|       A5|     其他|      普通企业|            公共服务、社会组织|  4 years|        1.0|              0.0|          2.0|     1.0|       5.0|2016-01-01|0.0|    108.0|  21.0|          12.14|           0.0|      675.0|       679.0|             0.0|         0.0|                0.0|                     0.0|   18811.0|      80.4|                0.0|          Dec-1996|    0.0|        1.0| 7.0| 0.0| 6.0|10.0| 7.0| 0.0|    1|      2.0|(6,[2],[1.0])|         10.0| (34,[10],[1.0])|          0.0|   (4,[0],[1.0])|              0.0|       (5,[0],[1.0])|         2.0| (13,[2],[1.0])|          6.0|  (11,[6],[1.0])|          11.0| (137,[11],[1.0])|                 115.0|        (685,[115],[1.0])|(926,[0,1,2,3,6,2...|\n",
      "+-------+-------+----------+------------+--------+---------------+-----+---------+---------+--------------+------------------------------+---------+-----------+-----------------+-------------+--------+----------+----------+---+---------+------+---------------+--------------+-----------+------------+----------------+------------+-------------------+------------------------+----------+----------+-------------------+------------------+-------+-----------+----+----+----+----+----+----+-----+---------+-------------+-------------+----------------+-------------+----------------+-----------------+--------------------+------------+---------------+-------------+----------------+--------------+-----------------+----------------------+-------------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = df.drop('label')\n",
    "feas = data.columns\n",
    "df_assembler = VectorAssembler(inputCols=['total_loan', 'year_of_loan', 'interest', 'monthly_payment', 'class_vector','sub_class_vector','work_type_vector','work_year_vector','employer_type_vector','industry_vector','issue_date_vector','earlies_credit_mon_vector','house_exist','house_loan_status','censor_status','marriage','offsprings','use','post_code','region','debt_loan_ratio','del_in_18month','scoring_low','scoring_high','pub_dero_bankrup','early_return','early_return_amount','early_return_amount_3mon','recircle_b','recircle_u','initial_list_status','title','policy_code','f0','f1','f2','f3','f4','f5'],outputCol='features')\n",
    "print(df_assembler)\n",
    "data = df_assembler.transform(df)\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec738df",
   "metadata": {},
   "source": [
    "# 划分数据集（8：2）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f499c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = data.select(['features', 'label'])\n",
    "train_df, test_df = data_set.randomSplit([0.8, 0.2])\n",
    "#print(' train_df shape : (%d , %d)'%(train_df.count(), len(train_df.columns)))\n",
    "#print(' test_df  shape: :(%d , %d)'%(test_df.count(), len(test_df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b49e53d",
   "metadata": {},
   "source": [
    "# 训练RFC模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d03ccdf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)\n",
    "RFC_reg = RandomForestClassifier(maxDepth=2).fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b29ab79",
   "metadata": {},
   "source": [
    "# LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1def7779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)\n",
    "RFC_reg = LinearSVC().fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05221c3e",
   "metadata": {},
   "source": [
    "# GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31acffd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)\n",
    "RFC_reg = GBTClassifier().fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c95eead",
   "metadata": {},
   "source": [
    "# 决策树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48a77fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)\n",
    "RFC_reg = DecisionTreeClassifier().fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57d496d",
   "metadata": {},
   "source": [
    "# OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e44b50fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)\n",
    "lr = LogisticRegression(regParam=0.01)\n",
    "ovr = OneVsRest(classifier=lr)\n",
    "RFC_reg = ovr.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3004d126",
   "metadata": {},
   "source": [
    "# NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c88ff98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    1|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "|(926,[0,1,2,3,4,1...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o596.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22.0 failed 1 times, most recent failure: Lost task 0.0 in stage 22.0 (TID 22, localhost, executor driver): java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found (926,[0,1,2,3,4,11,44,48,59,64,102,449,899,900,901,902,903,905,906,907,908,909,910,911,915,916,919,920,921,922,923,924],[8500.0,3.0,12.49,284.32,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0,3.0,567.0,9.0,7.06,1.0,675.0,679.0,1.0,2029.0,17.0,1.0,7.0,-1.0,25.0,17.0,13.0]).\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:176)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)\r\n\tat scala.util.Try$.apply(Try.scala:192)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.trainWithLabelCheck(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:118)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:78)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found (926,[0,1,2,3,4,11,44,48,59,64,102,449,899,900,901,902,903,905,906,907,908,909,910,911,915,916,919,920,921,922,923,924],[8500.0,3.0,12.49,284.32,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0,3.0,567.0,9.0,7.06,1.0,675.0,679.0,1.0,2029.0,17.0,1.0,7.0,-1.0,25.0,17.0,13.0]).\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7854df8dd051>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mRFC_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNaiveBayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\spark\\spark-2.4.8-bin-hadoop2.7\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m    130\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mE:\\spark\\spark-2.4.8-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-2.4.8-bin-hadoop2.7\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    290\u001b[0m         \"\"\"\n\u001b[0;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1257\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1258\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1259\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-2.4.8-bin-hadoop2.7\\python\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\spark\\spark-2.4.8-bin-hadoop2.7\\python\\lib\\py4j-0.10.7-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o596.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 22.0 failed 1 times, most recent failure: Lost task 0.0 in stage 22.0 (TID 22, localhost, executor driver): java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found (926,[0,1,2,3,4,11,44,48,59,64,102,449,899,900,901,902,903,905,906,907,908,909,910,911,915,916,919,920,921,922,923,924],[8500.0,3.0,12.49,284.32,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0,3.0,567.0,9.0,7.06,1.0,675.0,679.0,1.0,2029.0,17.0,1.0,7.0,-1.0,25.0,17.0,13.0]).\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1925)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1913)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1912)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1912)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:948)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:948)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2146)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2095)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2084)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:759)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2067)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2088)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2107)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2132)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:990)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:385)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:989)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:176)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1.apply(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.util.Instrumentation$$anonfun$11.apply(Instrumentation.scala:185)\r\n\tat scala.util.Try$.apply(Try.scala:192)\r\n\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:185)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.trainWithLabelCheck(NaiveBayes.scala:129)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:118)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:78)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.lang.reflect.Method.invoke(Method.java:498)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\r\n\tat java.lang.Thread.run(Thread.java:748)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found (926,[0,1,2,3,4,11,44,48,59,64,102,449,899,900,901,902,903,905,906,907,908,909,910,911,915,916,919,920,921,922,923,924],[8500.0,3.0,12.49,284.32,1.0,1.0,1.0,1.0,1.0,1.0,1.0,1.0,2.0,1.0,2.0,1.0,3.0,567.0,9.0,7.06,1.0,675.0,679.0,1.0,2029.0,17.0,1.0,7.0,-1.0,25.0,17.0,13.0]).\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:235)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$4.apply(NaiveBayes.scala:144)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:168)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$trainWithLabelCheck$1$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:62)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\r\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:411)\r\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:417)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "train_df.show(5)\n",
    "RFC_reg = NaiveBayes().fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22a0102",
   "metadata": {},
   "source": [
    "# 在测试集上做预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1d4351f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test0=test_df.drop('label')\n",
    "RFC_reg.transform(test0).head().prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a16339bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|            features|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    1|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    1|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    1|       1.0|\n",
      "|(926,[0,1,2,3,4,1...|    1|       1.0|\n",
      "|(926,[0,1,2,3,4,1...|    1|       1.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    1|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    1|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "|(926,[0,1,2,3,4,1...|    0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = RFC_reg.transform(test_df)\n",
    "predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2957d2",
   "metadata": {},
   "source": [
    "# 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "779327a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4694\n"
     ]
    }
   ],
   "source": [
    "tp=predictions.filter(\"label==1 and prediction==1\").count()\n",
    "tn=predictions.filter(\"label==0 and prediction==0\").count()\n",
    "fp=predictions.filter(\"label==0 and prediction==1\").count()\n",
    "fn=predictions.filter(\"label==1 and prediction==0\").count()\n",
    "print(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe16eb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45706\n",
      "2309\n",
      "7494\n"
     ]
    }
   ],
   "source": [
    "print(tn)\n",
    "print(fp)\n",
    "print(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a7e0373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy is : 0.837168\n",
      "test recall is : 0.385133\n",
      "test precision is : 0.670284\n",
      "test f1-score is : 0.489188\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy is : %f'%((tp+tn)/(tp+tn+fp+fn)))\n",
    "recal=tp/(tp+fn)\n",
    "prec=tp/(tp+fp)\n",
    "print('test recall is : %f'%(recal))\n",
    "print('test precision is : %f'%(prec))\n",
    "print('test f1-score is : %f'%(2*recal*prec/(prec+recal)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42cc7e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bceb92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
