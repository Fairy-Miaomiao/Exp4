{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "230b1cba",
   "metadata": {},
   "source": [
    "# 导包和pyspark环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b510ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark import SQLContext\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.sql.types import IntegerType\n",
    "sc = SparkContext(\"local\", \"first\")\n",
    "logFile = \"file:///F:/FBDP/实验/实验四/logfile1.txt\"  \n",
    "logData = sc.textFile(logFile).cache()\n",
    "spark = SparkSession.builder.config(\"spark.driver.memory\", \"16g\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a8b0030",
   "metadata": {},
   "source": [
    "# 统计所有用户所在公司类型 employer_type 的数量分布占比情况并存入csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "136d2e59",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "| employer_type| count|\n",
      "+--------------+------+\n",
      "|幼教与中小学校| 29995|\n",
      "|      上市企业| 30038|\n",
      "|      政府机构| 77446|\n",
      "|    世界五百强| 16112|\n",
      "|  高等教育机构| 10106|\n",
      "|      普通企业|136303|\n",
      "+--------------+------+\n",
      "\n",
      "+--------------+------------------------------------------------+\n",
      "| employer_type|(CAST(count AS DOUBLE) / CAST(300000 AS DOUBLE))|\n",
      "+--------------+------------------------------------------------+\n",
      "|幼教与中小学校|                             0.09998333333333333|\n",
      "|      上市企业|                             0.10012666666666667|\n",
      "|      政府机构|                             0.25815333333333335|\n",
      "|    世界五百强|                            0.053706666666666666|\n",
      "|  高等教育机构|                             0.03368666666666666|\n",
      "|      普通企业|                              0.4543433333333333|\n",
      "+--------------+------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SQLContext(sc)\n",
    "df=spark.read.options(header='True') .csv(\"file:///F:/FBDP/实验/实验四/train_data.csv\")\n",
    "#df.printSchema() #打印数据的树形结构\n",
    "#df.show()\n",
    "df.createOrReplaceTempView(\"debit\")#将DataFrame注册为SQL临时视图\n",
    "sqlDF = spark.sql(\"SELECT * FROM debit\")\n",
    "#sqlDF.show()\n",
    "emp_res=df.groupby('employer_type').count()\n",
    "emp_res.createOrReplaceTempView(\"employer\")\n",
    "emp_res.show()\n",
    "spark.sql(\"select employer_type,count/300000 from employer\").show()\n",
    "task3_1_df=spark.sql(\"select employer_type,count/300000 from employer\").toDF(\"employer_type\",\"ratio\")\n",
    "task3_1_df.toPandas().to_csv('task3_1_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f6275",
   "metadata": {},
   "source": [
    "# 统计每个用户最终须缴纳的利息金额并存入csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7045ab34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------------------------------------------------------------------------------------------------------------+\n",
      "|user_id|(((CAST(year_of_loan AS DOUBLE) * CAST(monthly_payment AS DOUBLE)) * CAST(12 AS DOUBLE)) - CAST(total_loan AS DOUBLE))|\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------+\n",
      "|      0|                                                                                                                3846.0|\n",
      "|      1|                                                                                                    1840.6000000000004|\n",
      "|      2|                                                                                                    10465.600000000002|\n",
      "|      3|                                                                                                    1758.5200000000004|\n",
      "|      4|                                                                                                     1056.880000000001|\n",
      "|      5|                                                                                                     7234.639999999999|\n",
      "|      6|                                                                                                     757.9200000000001|\n",
      "|      7|                                                                                                     4186.959999999999|\n",
      "|      8|                                                                                                    2030.7600000000002|\n",
      "|      9|                                                                                                    378.72000000000116|\n",
      "|     10|                                                                                                     4066.760000000002|\n",
      "|     11|                                                                                                    1873.5599999999977|\n",
      "|     12|                                                                                                     5692.279999999999|\n",
      "|     13|                                                                                                    1258.6800000000003|\n",
      "|     14|                                                                                                    6833.5999999999985|\n",
      "|     15|                                                                                                     9248.200000000004|\n",
      "|     16|                                                                                                     6197.119999999995|\n",
      "|     17|                                                                                                    1312.4400000000005|\n",
      "|     18|                                                                                                     5125.200000000001|\n",
      "|     19|                                                                                                    1215.8400000000001|\n",
      "+-------+----------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select user_id,year_of_loan*monthly_payment*12-total_loan from debit\").show()\n",
    "task3_2_df=spark.sql(\"select user_id,year_of_loan*monthly_payment*12-total_loan from debit\").toDF(\"user_id\",\"total_money\")\n",
    "task3_2_df.toPandas().to_csv('task3_2_output.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f89c75",
   "metadata": {},
   "source": [
    "# 统计工作年限 work_year 超过 5 年的⽤户的房贷情况 censor_status 的数量分布占比情况并存入csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f97a061b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+---------+\n",
      "|user_id|censor_status|work_year|\n",
      "+-------+-------------+---------+\n",
      "|      4|            0|  5 years|\n",
      "|      6|            0|  8 years|\n",
      "|     13|            1| < 1 year|\n",
      "|     15|            1|  7 years|\n",
      "|     20|            1|  7 years|\n",
      "|     31|            0|  6 years|\n",
      "|     37|            1|  5 years|\n",
      "|     40|            1|  6 years|\n",
      "|     44|            2| < 1 year|\n",
      "|     45|            1|  6 years|\n",
      "|     46|            0|  8 years|\n",
      "|     49|            0|  6 years|\n",
      "|     50|            1| < 1 year|\n",
      "|     53|            1|  7 years|\n",
      "|     54|            2| < 1 year|\n",
      "|     60|            1| < 1 year|\n",
      "|     63|            1|  5 years|\n",
      "|     66|            2|  7 years|\n",
      "|     67|            2| < 1 year|\n",
      "|     68|            1|  6 years|\n",
      "+-------+-------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#这有点问题\n",
    "spark.sql(\"select user_id,censor_status,work_year from debit where work_year>'5'\").show()\n",
    "task3_3_df=spark.sql(\"select user_id,censor_status,work_year from debit where work_year>'5'\")\n",
    "task3_3_df.toPandas().to_csv('task3_3_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd2322f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
